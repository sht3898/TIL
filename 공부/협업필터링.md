# 협업필터링 추천 시스템(Collaborative Filtering Recoomendation System)

## 추천 시스템 구현 방법

* 내용 기반(Content-based) 추천
  * 콘텐츠 내용 기반으로 추천
  * 사용자가 마블사의 영화를 봤다면, 이를 기반으로 마블사의 다른 영화를 추천
  * 텍스트 기반의 콘텐츠에서는 TF-IDF
* 협업 필터링
  * 많은 유저들로부터 모은 취향 정보들을 기반으로하여 스스로 예측하는 기술



## 협업 필터링(Collaborative Filtering)

### 종류

* Memory-based
* Model-based
* Hybrid



### Memory-Based

* 유사도를 기반으로 동작
* 사용자 기반(User-Based) - 사용자-사용자간의 유사도를 기준
* 아이템 기반(Item-Based) - 아이템-아이템간의 유사도를 기준



### 사용자 기반(User-Based)

* 유사도 - 두 사용자가 얼마나 유사한 항목(아이템)을 선호했는지를 기준
* 두 벡터 간의 유사도로 정의
* 코사인 유사도, 피어슨 유사도 많이 사용



### 아이템 기반(Item-Based)

* 사용자 기반에서 사용자에 대한 유사도를 구하는 것에서 아이템 간의 유사도를 구하는 것만 바뀜



### 사용자 기반 vs 아이템 기반

* 아마존과 넷플릭스를 비롯한 서비스에서는 대부분 아이템 기반을 활용



## Surprise 라이브러리 활용 knn 구현

### dataframe 불러오기

```python
def load_dataframes():
    # connect to DB
    con = sqlite3.connect("db.sqlite3") # 모듈 호출시 사용경로
    # print (os.getcwd()) #현재 디렉토리의
    # con = sqlite3.connect("../db.sqlite3") # main용
    cur = con.cursor()
    # read table 
    df_store = pd.read_sql_query("SELECT * from api_store", con)
    df_review = pd.read_sql_query("SELECT * from api_storereview", con)

    # clonse DB connection
    con.close()

    # select some columns
    stores = df_store.loc[:,['id','store_name','category','address']]
    reviews = df_review.loc[:,['user_id','store_id','total_score']]

    # rename columns and return data
    reviews.rename(columns={'total_score':'rating'}, inplace=True)
    stores.rename(columns={'id':'store_id'},inplace=True)

    df = pd.merge(reviews, stores, on="store_id")
    return df,stores
```

* sqlite3 라이브러리를 통해 sqlite에 저장되어 있는 데이터를 불러옴
* loc 함수를 통해 필요한 열만 뽑아옴
  * df.loc[행 인덱싱값] or df.lod[행 인덱싱값, 열 인덱싱값]



### 예측 모델 지정

```python
# 예측모델 지정해주기 ~~!
def set_algo(user_id,area=None):
    # dump file 지정
    file_name = os.path.expanduser('knn_file')

    # load dataframe
    df, stores = load_dataframes()
    #swapping columns
    raw=df.loc[:,['user_id','store_id','rating']] 
    # when importing from a DF, you only need to specify the scale of the ratings.
    reader = surprise.Reader(rating_scale=(0,5)) 
    #into surprise:
    dataframe = surprise.Dataset.load_from_df(raw,reader)
    trainset = dataframe.build_full_trainset()

    try:
        _, algo = surprise.dump.load(file_name)
     
    except FileNotFoundError:
        # 파일이 존재하지않는 경우
        print("Dump file Doesn't exists.")
        # Use the famous KNN algorithm.
        sim_options = {'name': 'pearson'}
        algo = surprise.KNNBasic(sim_options=sim_options)
        algo.fit(trainset)
        surprise.dump.dump(file_name, algo=algo)

    finally:
        # 전국 검색
        if area is None:
            iids = raw['store_id'].unique()
        else:
            tmp = df[df['address'].str.contains(area)]
            iids = tmp['store_id'].unique()
            
        iidsUsrnotVisited = raw.loc[raw['user_id']==user_id, 'store_id']
        iids_to_pred = np.setdiff1d(iids,iidsUsrnotVisited) # 안 간 가게 구함(차집합)
        # user_id가 가지않은 가게들로 testset 생성
        testset = [[user_id, iid, 4.] for iid in iids_to_pred]
        predictions = algo.test(testset)
        print(surprise.accuracy.rmse(predictions))
        pred_ratings = np.array([pred.est for pred in predictions])
        i_max = pred_ratings.argsort()[::-1][:5] # 역순으로 상위 5개
        #i_max = pred_ratings.argmax()
        iid = iids_to_pred[i_max]
        results = {}
        for i,m in zip(iid,i_max):
            # print('{0} : {1}'.format(i,pred_ratings[m]))
            results[i] = pred_ratings[m]
        return results
```

* os.path.expanduser(path)
  * 입력받은 경로안의 ~를 현재 사용자 디렉토리의 절대경로로 대체
  * ~에 붙여서 사용자명을 붙이면 원하는 사용자 경로로 대체
  * expanduser('~\\sht3898') => C\\Documents and Settings\Administrator\\sht3898
* setdiff1d(x, y) : 첫번째 배열 x로 부터 두번째 배열 y를 뺀 차집합을 반환
* 



## dataframe

* df.loc[행, 열] => 인덱스를 받음
* df.iloc[행, 열] => 인덱스 순서를 받음